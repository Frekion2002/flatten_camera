import cv2
import numpy as np
import time

# === ì„¤ì • ===
chessboard_size = (8, 6)       # ì²´ìŠ¤ë³´ë“œ ë‚´ë¶€ ì½”ë„ˆ ìˆ˜ (ê°€ë¡œ, ì„¸ë¡œ)
square_size = 0.025            # ê° ì‚¬ê°í˜•ì˜ í•œ ë³€ ê¸¸ì´ (ë¯¸í„° ë‹¨ìœ„)
video_path = "D:\\ComputerVision\\CV_image\\my_chessboard.mp4"
max_frames_to_use = 20         # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì— ì‚¬ìš©í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜
frame_skip = 10                # ëª‡ í”„ë ˆì„ë§ˆë‹¤ ì²´ìŠ¤ë³´ë“œ ê°ì§€ ì‹œë„

# === ì²´ìŠ¤ë³´ë“œ 3D ê°ì²´ í¬ì¸íŠ¸ ì„¤ì • ===
objp = np.zeros((chessboard_size[0]*chessboard_size[1], 3), np.float32)
objp[:, :2] = np.mgrid[0:chessboard_size[0], 0:chessboard_size[1]].T.reshape(-1, 2) * square_size

obj_points = []  # 3D ì‹¤ì„¸ê³„ ì¢Œí‘œ
img_points = []  # 2D ì´ë¯¸ì§€ ì¢Œí‘œ
image_size = None

# ì½”ë„ˆ ì •ì œ ê¸°ì¤€
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# === ë™ì˜ìƒ ë¡œë“œ ===
cap = cv2.VideoCapture(video_path)
if not cap.isOpened():
    print("âŒ ì˜¤ë¥˜: ë™ì˜ìƒì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

frame_idx = 0
collected = 0

print("ğŸ“· ì²´ìŠ¤ë³´ë“œ ê°ì§€ ì‹œì‘ (ê°ì§€ë˜ë©´ 'q'ë¡œ ì¤‘ë‹¨ ê°€ëŠ¥)...")
while cap.isOpened():
    ret, frame = cap.read()
    if not ret or collected >= max_frames_to_use:
        break

    frame_idx += 1
    if frame_idx % frame_skip != 0:
        continue

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    found, corners = cv2.findChessboardCorners(gray, chessboard_size, None)
    if found:
        if image_size is None:
            image_size = gray.shape[::-1]

        corners_sub = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)
        obj_points.append(objp)
        img_points.append(corners_sub)
        collected += 1

        cv2.drawChessboardCorners(frame, chessboard_size, corners_sub, found)
        print(f"âœ… ì²´ìŠ¤ë³´ë“œ ê°ì§€ë¨: {collected}/{max_frames_to_use}")

    cv2.imshow("Chessboard Detection", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# === ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ===
if len(obj_points) >= 3:
    print("\nğŸ§® ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘...")
    start_time = time.time()
    try:
        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
            obj_points, img_points, image_size, None, None)
        elapsed = time.time() - start_time

        print("\nâœ… ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì„±ê³µ!")
        print("ì¹´ë©”ë¼ ë§¤íŠ¸ë¦­ìŠ¤:\n", mtx)
        print("\nì™œê³¡ ê³„ìˆ˜:\n", dist.ravel())
        print(f"\nğŸ“‰ RMSE (ì¬íˆ¬ì˜ ì˜¤ì°¨): {ret:.4f}")
        print(f"â± ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

        # ê²°ê³¼ ì €ì¥
        np.savez('calibration_data.npz', mtx=mtx, dist=dist)
        print("ğŸ’¾ ê²°ê³¼ê°€ 'calibration_data.npz'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except cv2.error as e:
        print("âŒ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", e)
else:
    print("âš ï¸ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ì„ ìœ„í•œ ì¶©ë¶„í•œ ì²´ìŠ¤ë³´ë“œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
